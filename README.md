# ğŸš€ P&ID Analyzer v2.0

Professionelles KI-System fÃ¼r die automatisierte Analyse von P&ID (Piping & Instrumentation Diagram) Diagrammen mit Google Gemini AI.

## ğŸ“‹ Ãœbersicht

Der P&ID Analyzer ist ein hochmodernes System zur automatischen Erkennung und Extraktion von Komponenten, Verbindungen und Topologie aus P&ID-Diagrammen. Das System verwendet eine modulare Pipeline-Architektur mit mehreren Analyse-Phasen und unterstÃ¼tzt sowohl einfache als auch komplexe Diagramme.

### ğŸ¯ Hauptfunktionen

- âœ… **Automatische Element-Erkennung**: Pumpen, Ventile, Sensoren, Mischer, etc.
- âœ… **Verbindungs-Analyse**: Automatische Erkennung von Pipeline-Verbindungen
- âœ… **Topologie-Validierung**: Graph-basierte KonsistenzprÃ¼fung
- âœ… **Legenden-Erkennung**: Automatische Extraktion von Symbol-Mappings
- âœ… **Selbstkorrektur**: Iterative Verbesserung der Analyse-Ergebnisse
- âœ… **CGM-Generierung**: Python dataclass und JSON-Output
- âœ… **Comprehensive KPIs**: Precision, Recall, F1-Score, Quality Score
- âœ… **Active Learning**: Kontinuierliche Verbesserung durch Lernen aus Fehlern

---

## ğŸ—ï¸ Pipeline-Architektur

Das System verwendet eine modulare Phase-basierte Architektur:

### **Phase 0: Complexity Analysis (CV-basiert)**
- **Zweck**: Schnelle KomplexitÃ¤tserkennung fÃ¼r Strategie-Auswahl
- **Prozess**: CV-basierte Multi-Metrik-Analyse (Edge Density, Object Density, Junctions)
- **Output**: Strategie-Name (`simple_pid_strategy` oder `optimal_swarm_monolith`)
- **Datei**: `src/analyzer/core/pipeline_coordinator.py` â†’ `_run_phase_0_complexity_analysis()`

### **Phase 1: Pre-Analysis**
- **1.1 Metadata Extraction**: Extrahiert Titel, Projekt, Datum, Version
- **1.2 Legend Extraction**: Erkennt und extrahiert Symbol- und Line-Mappings aus der Legende
- **Output**: Global Knowledge Repository (Metadata, Symbol-Map, Line-Map)
- **Datei**: `src/analyzer/core/pipeline_coordinator.py` â†’ `_run_phase_1_pre_analysis()`

### **Phase 2: Core Analysis**

#### **2a: Swarm Analysis (Element-Erkennung)**
- **Zweck**: Tile-basierte Detail-Analyse fÃ¼r Element-Erkennung
- **Prozess**: Bild wird in Kacheln aufgeteilt, jede Kachel wird einzeln analysiert
- **Output**: Liste aller erkannten Elemente (Symbole, Text-Labels)
- **Datei**: `src/analyzer/analysis/swarm_analyzer.py`
- **Besonderheit**: Ignoriert Verbindungen (nur Element-Erkennung)

#### **2b: Guard Rails (Inference Rules)**
- **Zweck**: Bereinigung und Anreicherung der Element-Liste
- **Prozess**: 
  - SamplePoint-S: `id == 'S'` â†’ `type = 'Sample Point'`
  - ISA-Supply: `'isa' in id/label` â†’ `type = 'Source'`
  - Confidence-Boost fÃ¼r alle Elemente
- **Output**: Bereinigte Element-Liste
- **Datei**: `src/analyzer/core/pipeline_coordinator.py` â†’ Guard Rails Logic

#### **2c: Monolith Analysis (Verbindungs-Erkennung)**
- **Zweck**: Globale Struktur-Analyse fÃ¼r Verbindungs-Erkennung
- **Prozess**: Analysiert das gesamte Bild (oder Quadranten) und erkennt Verbindungen zwischen Elementen
- **Input**: Element-Liste von Swarm (als JSON)
- **Output**: Liste aller erkannten Verbindungen
- **Datei**: `src/analyzer/analysis/monolith_analyzer.py`
- **Besonderheit**: Nutzt Element-Liste als Knowledge Base

#### **2d: Fusion Engine**
- **Zweck**: Kombiniert Swarm- und Monolith-Ergebnisse
- **Prozess**: 
  - Deduplizierung (IoU-basiert)
  - Confidence-Propagation
  - Element-Merging
- **Output**: Kombinierte Element- und Verbindungs-Liste
- **Datei**: `src/analyzer/analysis/fusion_engine.py`

#### **2e: Predictive Completion**
- **Zweck**: VervollstÃ¤ndigt fehlende Verbindungen
- **Prozess**: Geometrische Heuristiken (Distanz, Position)
- **Output**: VervollstÃ¤ndigte Verbindungs-Liste
- **Datei**: `src/analyzer/core/pipeline_coordinator.py` â†’ `_run_phase_2d_predictive_completion()`

#### **2f: Polyline Refinement**
- **Zweck**: Extrahiert prÃ¤zise Polylinien fÃ¼r Verbindungen
- **Prozess**: 
  - Option 1: LLM-basiert (Standard)
  - Option 2: Skeleton-basiert (prÃ¤ziser, aber langsamer)
- **Output**: Polylinien-Koordinaten fÃ¼r jede Verbindung
- **Datei**: `src/analyzer/core/pipeline_coordinator.py` â†’ `_run_phase_2e_polyline_refinement()`

### **Phase 3: Self-Correction Loop**
- **Zweck**: Iterative Selbstkorrektur der Analyse-Ergebnisse
- **Prozess**:
  1. **Topology Critic**: Validiert Graph-Konsistenz (Disconnected nodes, Invalid degrees, Missing splits/merges)
  2. **Legend Consistency Critic**: PrÃ¼ft Konsistenz zwischen Legende und erkannten Symbolen
  3. **Multi-Model Critic**: Visuelle Feedback-Validierung
  4. **Re-Analyse**: Problematische Bereiche werden erneut analysiert
  5. **Plateau-Erkennung**: Stoppt bei keinem Fortschritt
- **Output**: Verbesserte Analyse-Ergebnisse
- **Datei**: `src/analyzer/core/pipeline_coordinator.py` â†’ `_run_phase_3_self_correction()`
- **Max. Iterationen**: 15 (konfigurierbar)

### **Phase 4: Post-Processing**
- **4.1 KPI-Berechnung**: Precision, Recall, F1-Score, Quality Score
- **4.2 CGM-Generierung**: Python dataclass und JSON-Output
- **4.3 Visualisierungen**: Confidence Maps, Debug Maps, Score Curves
- **4.4 Active Learning**: Speichert gelernte Patterns
- **Output**: Finale Analyse-Ergebnisse, Visualisierungen, Reports
- **Datei**: `src/analyzer/core/pipeline_coordinator.py` â†’ `_run_phase_4_post_processing()`

---

## ğŸ“ Projektstruktur

```
pid_analyzer_v2/
â”œâ”€â”€ src/                          # Haupt-Code
â”‚   â”œâ”€â”€ analyzer/                 # Analyse-Komponenten
â”‚   â”‚   â”œâ”€â”€ core/                 # Pipeline Coordinator
â”‚   â”‚   â”œâ”€â”€ analysis/             # Swarm, Monolith, Fusion
â”‚   â”‚   â”œâ”€â”€ learning/             # Knowledge Manager, Active Learner
â”‚   â”‚   â”œâ”€â”€ evaluation/           # KPI Calculator
â”‚   â”‚   â”œâ”€â”€ output/               # CGM Generator
â”‚   â”‚   â”œâ”€â”€ visualization/        # Visualizer
â”‚   â”‚   â””â”€â”€ models/               # Pydantic Models
â”‚   â”œâ”€â”€ services/                 # Services (Config, Logging)
â”‚   â”œâ”€â”€ utils/                    # Utilities
â”‚   â”œâ”€â”€ gui/                      # GUI (tkinter)
â”‚   â””â”€â”€ interfaces/               # ABC Interfaces
â”œâ”€â”€ scripts/                      # Skripte
â”‚   â”œâ”€â”€ validation/               # Test-Skripte
â”‚   â”œâ”€â”€ training/                 # Training-Skripte
â”‚   â”œâ”€â”€ utilities/                # Utility-Skripte
â”‚   â””â”€â”€ utils/                    # Script-Utilities
â”œâ”€â”€ training_data/                # Training-Daten
â”‚   â”œâ”€â”€ simple_pids/              # Einfache P&IDs
â”‚   â”œâ”€â”€ complex_pids/             # Komplexe P&IDs
â”‚   â”œâ”€â”€ viewshot_examples/        # Viewshot-Beispiele
â”‚   â””â”€â”€ learning_db.json          # Learning Database
â”œâ”€â”€ outputs/                      # Output-Ordner
â”‚   â”œâ”€â”€ live_test/                # Live-Test-Outputs
â”‚   â”œâ”€â”€ overnight_optimization/   # Overnight-Test-Outputs
â”‚   â””â”€â”€ ...
â”œâ”€â”€ docs/                         # Dokumentation
â”œâ”€â”€ config.yaml                   # Haupt-Konfigurationsdatei
â”œâ”€â”€ requirements.txt              # Python-Dependencies
â”œâ”€â”€ run_cli.py                    # CLI-Starter
â”œâ”€â”€ run_gui.py                    # GUI-Starter
â””â”€â”€ README.md                     # Diese Datei
```

---

## ğŸš€ Schnellstart

### 1. Dependencies installieren

```bash
pip install -r requirements.txt
```

### 2. Umgebungsvariablen setzen

Erstelle `.env` Datei im Projekt-Root:

```bash
GCP_PROJECT_ID=dein_project_id
GCP_LOCATION=us-central1
```

### 3. Vector-Indizes erstellen (Optional, aber empfohlen)

```bash
python scripts/training/build_vector_indices.py
```

Dies beschleunigt den Startup erheblich.

### 4. Erste Analyse starten

**CLI:**
```bash
python run_cli.py path/to/image.png
```

**GUI:**
```bash
python run_gui.py
```

**Live-Test (mit Log-Monitoring):**
```bash
python scripts/validation/run_live_test.py
```

---

## ğŸ“š Wichtige Skripte

### Test-Skripte (`scripts/validation/`)

- **`run_live_test.py`** â­ **HAUPT-TEST-SKRIPT**
  - FÃ¼hrt einen vollstÃ¤ndigen Test mit Live-Log-Monitoring durch
  - Verwendet strukturierte Output-Ordner
  - Zeigt Logs live im Terminal an

- **`run_simple_test.py`**
  - Einfacher Test-Runner fÃ¼r schnelle Tests
  - Testet eine einzelne Konfiguration

- **`run_strategy_validation.py`**
  - Strategy-Validation-Tests
  - FÃ¼hrt mehrere Strategien nacheinander aus
  - Berechnet KPIs fÃ¼r jede Strategie

- **`run_overnight_optimization.py`**
  - Overnight A/B Testing
  - FÃ¼hrt automatische A/B-Tests zwischen Strategien durch
  - Generiert umfassende Reports

### Monitoring-Skripte (`scripts/validation/`)

- **`monitor_overnight.py`**: Ãœberwacht Overnight-Prozess
- **`watchdog_overnight.py`**: Watchdog fÃ¼r Overnight
- **`auto_guardian.py`**: Auto-Guardian fÃ¼r Ãœberwachung
- **`continuous_monitor.py`**: Kontinuierlicher Monitor
- **`test_startup_speed.py`**: Startup-Speed-Test
- **`diagnose_hang.py`**: Diagnose-Tool fÃ¼r Hangs

### Training-Skripte (`scripts/training/`)

- **`build_vector_indices.py`**: Erstellt Vektor-Indizes (schneller Startup)
- **`run_pretraining.py`**: Symbol-Pretraining
- **`run_pretraining_stepwise.py`**: Stepwise Pretraining

### Utility-Skripte (`scripts/utilities/`)

- **`backup_learning_db.py`**: Backup der Learning DB
- **`restore_learning_db.py`**: Restore der Learning DB
- **`reset_learning_db.py`**: Reset der Learning DB
- **`cleanup_outputs.py`**: AufrÃ¤umen der Output-Ordner
- **`extract_viewshots_from_pretraining_pdf.py`**: Viewshot-Extraktion (PDF)
- **`extract_viewshots_from_uni_bilder.py`**: Viewshot-Extraktion (Uni)

---

## ğŸ”§ Hauptkomponenten

### **PipelineCoordinator** (`src/analyzer/core/pipeline_coordinator.py`)
- **Zweck**: Orchestriert alle Pipeline-Phasen
- **Funktionen**: 
  - Phase 0-4 AusfÃ¼hrung
  - Progress-Callbacks
  - Error-Handling
  - Output-Generierung

### **SwarmAnalyzer** (`src/analyzer/analysis/swarm_analyzer.py`)
- **Zweck**: Tile-basierte Element-Erkennung
- **Funktionen**:
  - Bild-Tiling
  - Parallele Kachel-Analyse
  - Element-Erkennung
  - Viewshot-Integration

### **MonolithAnalyzer** (`src/analyzer/analysis/monolith_analyzer.py`)
- **Zweck**: Globale Verbindungs-Erkennung
- **Funktionen**:
  - Ganzbild-Analyse
  - Quadrant-basierte Analyse
  - Verbindungs-Erkennung
  - Port-Detection

### **FusionEngine** (`src/analyzer/analysis/fusion_engine.py`)
- **Zweck**: Kombiniert Swarm- und Monolith-Ergebnisse
- **Funktionen**:
  - IoU-basierte Deduplizierung
  - Confidence-Propagation
  - Element-Merging

### **KnowledgeManager** (`src/analyzer/learning/knowledge_manager.py`)
- **Zweck**: Verwaltet statisches und dynamisches Wissen
- **Funktionen**:
  - Element-Type-Resolution
  - Similarity-Search
  - Learning-Database-Management
  - Vector-Index-Loading

### **ActiveLearner** (`src/analyzer/learning/active_learner.py`)
- **Zweck**: Kontinuierliches Lernen aus Fehlern
- **Funktionen**:
  - Pattern-Erkennung
  - Correction-Learning
  - Knowledge-Update

### **KPICalculator** (`src/analyzer/evaluation/kpi_calculator.py`)
- **Zweck**: Berechnet Comprehensive KPIs
- **Funktionen**:
  - Precision, Recall, F1-Score
  - Quality Score
  - Connection-Matching
  - Element-Matching

### **CGMGenerator** (`src/analyzer/output/cgm_generator.py`)
- **Zweck**: Generiert CGM-Daten (Python dataclass + JSON)
- **Funktionen**:
  - Network-Instanz-Generierung
  - Connector-Generierung
  - System-Flow-Generierung

---

## âš™ï¸ Konfiguration

Die Haupt-Konfigurationsdatei ist `config.yaml`. Wichtige Bereiche:

### **Strategien** (`strategies/`)
- `simple_whole_image`: Einfache P&IDs (Monolith-Only)
- `default_flash`: Flash-Strategie (schnell)
- `optimal_swarm_monolith`: Optimale Strategie (Swarm + Monolith)

### **Modelle** (`model_strategy/`)
- `swarm_model`: Modell fÃ¼r Swarm-Analyse
- `monolith_model`: Modell fÃ¼r Monolith-Analyse
- `critic_model`: Modell fÃ¼r Critics

### **Logik-Parameter** (`logic_parameters/`)
- `use_swarm_analysis`: Swarm-Analyse aktivieren
- `use_monolith_analysis`: Monolith-Analyse aktivieren
- `use_fusion`: Fusion aktivieren
- `use_phase_3`: Self-Correction aktivieren
- `max_iterations`: Max. Iterationen fÃ¼r Self-Correction

---

## ğŸ“Š Output-Struktur

Alle Outputs folgen einer standardisierten Struktur:

```
outputs/
  {test_type}/                    # z.B. live_test, overnight_optimization
    YYYYMMDD_HHMMSS/              # Timestamp fÃ¼r jeden Testlauf
      logs/                       # Log-Dateien
        test.log
      visualizations/             # Visualisierungen
        {image_name}_score_curve.png
        {image_name}_confidence_map.png
        {image_name}_debug_map.png
      data/                       # Daten (JSON, Python)
        {image_name}_results.json
        {image_name}_cgm_data.json
        {image_name}_cgm_network_generated.py
        {image_name}_kpis.json
      artifacts/                  # Artefakte (Config, Reports)
        config_snapshot.yaml
        {image_name}_report.html
      temp/                       # TemporÃ¤re Dateien
        temp_quadrants/
        temp_polylines/
      README.md                   # ErklÃ¤rt die Struktur
```

---

## ğŸ“– Dokumentation

Alle Dokumentationen finden Sie im **[docs/](docs/)** Ordner:

- **[Pipeline-Dokumentation](docs/PIPELINE_PROCESS_DETAILED.md)**: Detaillierte Prozessbeschreibung
- **[Output-Struktur](docs/OUTPUT_STRUCTURE_STANDARD.md)**: Gold Standard fÃ¼r Output-Ordner
- **[Overnight-Optimization](docs/OVERNIGHT_OPTIMIZATION_GUIDE.md)**: Anleitung fÃ¼r Overnight-Tests
- **[Test-Strategie](tests/STRATEGY_VALIDATION.md)**: Strategy-Validation-Tests

---

## ğŸ¯ Features im Detail

### **Graphentheorie (NetworkX)**
- Graph-basierte ReprÃ¤sentation der P&ID-Topologie
- Split/Merge-Detection
- Pipeline-Flow-Analyse

### **CGM Format**
- Python dataclass-Format fÃ¼r Code-Generierung
- JSON-Format fÃ¼r Daten-Austausch
- System-Flow-Generierung

### **Active Learning**
- Kontinuierliches Lernen aus Fehlern
- Pattern-Erkennung
- Knowledge-Update

### **Comprehensive KPIs**
- Element-Precision, Recall, F1-Score
- Connection-Precision, Recall, F1-Score
- Quality Score (gewichteter Durchschnitt)
- Hallucination-Detection

---

## ğŸ” Troubleshooting

### Problem: Startup hÃ¤ngt
**LÃ¶sung**: FÃ¼hre `python scripts/training/build_vector_indices.py` aus, um Vektor-Indizes zu erstellen.

### Problem: GCP-Credentials fehlen
**LÃ¶sung**: Erstelle `.env` Datei mit `GCP_PROJECT_ID` und `GCP_LOCATION`.

### Problem: Output-Ordner unorganisiert
**LÃ¶sung**: Das System verwendet automatisch strukturierte Output-Ordner. PrÃ¼fe `docs/OUTPUT_STRUCTURE_STANDARD.md`.

### Problem: Tests schlagen fehl
**LÃ¶sung**: PrÃ¼fe Logs in `outputs/{test_type}/YYYYMMDD_HHMMSS/logs/test.log`.

---

## ğŸ“ License

[Lizenz-Informationen hier einfÃ¼gen]

---

## ğŸ‘¥ Contributors

[Contributor-Informationen hier einfÃ¼gen]

---

**Status:** âœ… System ist PRODUCTION-READY und vollstÃ¤ndig dokumentiert!

**Letzte Aktualisierung:** 2025-11-07
