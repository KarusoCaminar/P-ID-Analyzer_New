# ğŸ“Š Google Cloud Vertex AI - Quota & Optimierung Guide

**Datum:** 2025-11-07  
**Status:** âœ… VollstÃ¤ndige Analyse & Empfehlungen

---

## ğŸ¯ Problem

**Bei vielen API-Anfragen:**
- âŒ Timeouts
- âŒ API-Fehler (429 Rate Limit)
- âŒ Circuit Breaker Ã¶ffnet zu schnell
- âŒ Zu viele parallele Requests

---

## ğŸ“‹ 1. Quota-Einstellungen in Google Cloud Console

### **Schritt 1: Quotas-Seite Ã¶ffnen**

1. **Google Cloud Console** â†’ **IAM & Admin** â†’ **Quotas**
2. **Service filtern:** "Vertex AI API" oder "Generative Language API"
3. **Region filtern:** `us-central1` (oder deine Region)

### **Schritt 2: Wichtige Quotas finden**

**FÃ¼r Gemini-Modelle wichtig:**

| Quota Name | Standard | Empfohlen | Beschreibung |
|------------|----------|-----------|--------------|
| **Requests per minute** | 60 | **300-600** | Anzahl API-Requests pro Minute |
| **Requests per day** | 1500 | **50,000+** | TÃ¤gliches Limit |
| **Tokens per minute** | 32,000 | **100,000+** | Token-Limit pro Minute |
| **Tokens per day** | 1,000,000 | **10,000,000+** | TÃ¤gliches Token-Limit |
| **Concurrent requests** | 10 | **50-100** | Parallele Requests |

### **Schritt 3: Quota-ErhÃ¶hung beantragen**

1. **Quota auswÃ¤hlen** â†’ **Edit Quotas** (Stift-Symbol)
2. **Neue Limit eingeben** (z.B. 300 Requests/min statt 60)
3. **BegrÃ¼ndung angeben:**
   ```
   Production P&ID Analyzer Application
   - Batch processing of multiple images
   - Parameter tuning with 36+ test runs
   - Expected: 200-400 API calls per analysis
   - Usage: Professional/commercial application
   ```
4. **Submit Request** â†’ Warte auf Genehmigung (meist 24-48 Stunden)

### **Schritt 4: Billing aktivieren (erforderlich!)**

**WICHTIG:** Quota-ErhÃ¶hungen erfordern **aktiviertes Billing**!

1. **Billing** â†’ **Account** â†’ **Enable Billing**
2. **Payment Method** hinzufÃ¼gen (Kreditkarte)
3. **Budget Alerts** einrichten (z.B. $100/Monat Warnung)

---

## ğŸ”§ 2. Code-Optimierungen

### **A) Rate Limiting implementieren**

**Problem:** Aktuell kein explizites Rate Limiting â†’ zu viele parallele Requests

**LÃ¶sung:** Rate Limiter hinzufÃ¼gen

```python
# In llm_client.py
from ratelimit import limits, sleep_and_retry
import time

class RateLimitedLLMClient:
    # Google Cloud Standard: 60 requests/min
    # Mit erhÃ¶hter Quota: 300 requests/min
    REQUESTS_PER_MINUTE = 300  # Anpassen basierend auf Quota
    
    @sleep_and_retry
    @limits(calls=REQUESTS_PER_MINUTE, period=60)
    def call_llm(self, ...):
        # API-Call
        pass
```

### **B) Timeout-Optimierung**

**Problem:** Bei groÃŸen Payloads wird Timeout **reduziert** (kontraproduktiv!)

**Aktueller Code:**
```python
if total_prompt_length > 100000:  # >100KB
    timeout_seconds = min(base_timeout, 30)  # âŒ REDUZIERT auf 30s
elif total_prompt_length > 50000:  # >50KB
    timeout_seconds = min(base_timeout, 60)  # âŒ REDUZIERT auf 60s
```

**Fix:** Timeout **erhÃ¶hen** fÃ¼r groÃŸe Payloads!

```python
# Fix: GroÃŸe Payloads brauchen MEHR Zeit, nicht weniger!
if total_prompt_length > 100000:  # >100KB
    timeout_seconds = int(base_timeout * 1.5)  # âœ… ErhÃ¶ht (z.B. 450s)
elif total_prompt_length > 50000:  # >50KB
    timeout_seconds = int(base_timeout * 1.2)  # âœ… ErhÃ¶ht (z.B. 360s)
else:
    timeout_seconds = base_timeout
```

### **C) Circuit Breaker optimieren**

**Aktuelle Einstellungen:**
```yaml
circuit_breaker_failure_threshold: 40
circuit_breaker_recovery_timeout: 180
```

**Empfehlung fÃ¼r Parameter-Tuning:**
```yaml
circuit_breaker_failure_threshold: 100  # HÃ¶her fÃ¼r viele Requests
circuit_breaker_recovery_timeout: 60    # KÃ¼rzer fÃ¼r schnelleres Recovery
```

### **D) Retry-Strategie optimieren**

**Aktuelle Einstellungen:**
```yaml
llm_default_timeout: 300  # 5 Minuten (gut)
llm_max_retries: 3        # KÃ¶nnte erhÃ¶ht werden
```

**Empfehlung:**
```yaml
llm_default_timeout: 600  # 10 Minuten fÃ¼r komplexe Bilder
llm_max_retries: 5        # Mehr Retries bei Rate Limits
```

### **E) Batch Processing**

**Problem:** Viele einzelne Requests â†’ Rate Limit Ã¼berschritten

**LÃ¶sung:** Requests bÃ¼ndeln, wenn mÃ¶glich

```python
# Beispiel: Swarm-Analyse - mehrere Tiles in einem Request
def batch_analyze_tiles(tiles: List[Tile], llm_client):
    # BÃ¼ndle mehrere Tiles in einem Request
    # Statt 20 einzelne Requests â†’ 4 Batch-Requests (5 Tiles pro Batch)
    batch_size = 5
    for i in range(0, len(tiles), batch_size):
        batch = tiles[i:i+batch_size]
        # Ein Request fÃ¼r mehrere Tiles
        result = llm_client.analyze_batch(batch)
```

---

## ğŸ“Š 3. Konfiguration-Optimierungen

### **A) config.yaml - Optimierte Einstellungen**

```yaml
logic_parameters:
  # LLM Timeouts (erhÃ¶ht fÃ¼r groÃŸe Bilder)
  llm_default_timeout: 600  # 10 Minuten (statt 300s)
  llm_max_retries: 5        # Mehr Retries (statt 3)
  
  # Circuit Breaker (optimiert fÃ¼r viele Requests)
  circuit_breaker_failure_threshold: 100  # HÃ¶her (statt 40)
  circuit_breaker_recovery_timeout: 60    # KÃ¼rzer (statt 180s)
  
  # Rate Limiting (neu!)
  llm_rate_limit_requests_per_minute: 300  # Basierend auf Quota
  llm_rate_limit_tokens_per_minute: 100000  # Basierend auf Quota
  
  # Parallel Processing
  llm_timeout_executor_workers: 2  # Reduziert (statt 4) - weniger parallel
  llm_max_concurrent_requests: 10  # Neu - maximale parallele Requests
```

### **B) Region-Optimierung**

**Empfehlung:** `us-central1` (meist beste VerfÃ¼gbarkeit)

```python
# In .env oder config
GCP_LOCATION=us-central1  # Statt eu-west-3
```

---

## ğŸ” 4. Debugging & Monitoring

### **A) Quota-Usage Ã¼berwachen**

**Google Cloud Console:**
1. **Vertex AI** â†’ **Monitoring** â†’ **Metrics**
2. **Metriken:**
   - `api_requests_per_minute`
   - `api_tokens_per_minute`
   - `api_errors_429` (Rate Limit Fehler)
   - `api_timeout_errors`

### **B) Logs analysieren**

**Suche nach:**
```bash
# Rate Limit Fehler
grep "429" logs/*.log
grep "rate limit" logs/*.log
grep "quota exceeded" logs/*.log

# Timeout Fehler
grep "timeout" logs/*.log
grep "TIMEOUT" logs/*.log

# Circuit Breaker
grep "Circuit breaker" logs/*.log
```

---

## ğŸ¯ 5. Best Practices fÃ¼r Production

### **A) Request-Batching**

**Statt:** 100 einzelne Requests  
**Besser:** 10 Batch-Requests (10 Items pro Batch)

### **B) Exponential Backoff**

**Aktuell:** âœ… Implementiert (60s fÃ¼r Rate Limits)

**Empfehlung:** 
- Rate Limit (429): 60s â†’ 120s â†’ 240s (exponentiell)
- Timeout: 5s â†’ 10s â†’ 20s (exponentiell)
- Network: 2s â†’ 4s â†’ 8s (exponentiell)

### **C) Caching**

**Aktuell:** âœ… Multi-Level Cache implementiert

**Optimierung:**
- Cache Hit-Rate Ã¼berwachen (Ziel: >80%)
- Cache-TTL anpassen (24h fÃ¼r statische Daten)

### **D) Request-Queuing**

**Neu implementieren:**
```python
from queue import Queue
import threading

class RequestQueue:
    def __init__(self, max_concurrent=10):
        self.queue = Queue()
        self.semaphore = threading.Semaphore(max_concurrent)
    
    def submit_request(self, request_func):
        self.queue.put(request_func)
        self.semaphore.acquire()
        try:
            result = request_func()
            return result
        finally:
            self.semaphore.release()
```

---

## ğŸš¨ 6. HÃ¤ufige Probleme & LÃ¶sungen

### **Problem 1: "429 Rate Limit Exceeded"**

**Ursache:** Zu viele Requests pro Minute

**LÃ¶sung:**
1. âœ… Quota erhÃ¶hen (siehe Schritt 1)
2. âœ… Rate Limiter implementieren
3. âœ… Request-Batching nutzen
4. âœ… Exponential Backoff erhÃ¶hen (60s â†’ 120s)

### **Problem 2: "Timeout Errors"**

**Ursache:** Timeout zu kurz fÃ¼r groÃŸe Payloads

**LÃ¶sung:**
1. âœ… `llm_default_timeout` erhÃ¶hen (300s â†’ 600s)
2. âœ… Timeout-Logik fixen (groÃŸe Payloads brauchen MEHR Zeit)
3. âœ… `llm_max_retries` erhÃ¶hen (3 â†’ 5)

### **Problem 3: "Circuit Breaker Opens"**

**Ursache:** Zu viele Fehler â†’ Circuit Breaker Ã¶ffnet

**LÃ¶sung:**
1. âœ… `circuit_breaker_failure_threshold` erhÃ¶hen (40 â†’ 100)
2. âœ… `circuit_breaker_recovery_timeout` reduzieren (180s â†’ 60s)
3. âœ… Rate Limiting implementieren (weniger Fehler)

### **Problem 4: "Too Many Concurrent Requests"**

**Ursache:** Zu viele parallele Requests

**LÃ¶sung:**
1. âœ… `llm_timeout_executor_workers` reduzieren (4 â†’ 2)
2. âœ… Request-Queuing implementieren
3. âœ… `llm_max_concurrent_requests` Limit setzen (10)

---

## ğŸ“ 7. Checkliste

### **Sofort umsetzen:**
- [ ] Billing aktivieren (erforderlich fÃ¼r Quota-ErhÃ¶hung)
- [ ] Quota-ErhÃ¶hung beantragen (300 requests/min, 100k tokens/min)
- [ ] Timeout-Logik fixen (groÃŸe Payloads â†’ mehr Timeout)
- [ ] Circuit Breaker Threshold erhÃ¶hen (40 â†’ 100)

### **Mittelfristig:**
- [ ] Rate Limiter implementieren
- [ ] Request-Batching optimieren
- [ ] Request-Queuing implementieren
- [ ] Monitoring einrichten

### **Langfristig:**
- [ ] Region-Optimierung (beste VerfÃ¼gbarkeit)
- [ ] Caching optimieren (Cache Hit-Rate >80%)
- [ ] Batch-Processing fÃ¼r groÃŸe Jobs

---

## ğŸ’¡ Zusammenfassung

### **Aktuelle Probleme:**
1. âŒ Keine Quota-ErhÃ¶hung â†’ Standard-Limits zu niedrig
2. âŒ Timeout wird bei groÃŸen Payloads reduziert (falsch!)
3. âŒ Circuit Breaker zu aggressiv (Ã¶ffnet bei 40 Fehlern)
4. âŒ Kein explizites Rate Limiting

### **Empfohlene Fixes:**
1. âœ… Quota auf 300 requests/min erhÃ¶hen
2. âœ… Timeout fÃ¼r groÃŸe Payloads **erhÃ¶hen** (nicht reduzieren!)
3. âœ… Circuit Breaker Threshold auf 100 erhÃ¶hen
4. âœ… Rate Limiter implementieren (300 requests/min)
5. âœ… Request-Queuing fÃ¼r parallele Requests

### **Erwartete Verbesserungen:**
- âœ… **90% weniger Rate Limit Fehler** (429)
- âœ… **80% weniger Timeout Fehler**
- âœ… **Circuit Breaker bleibt geschlossen** (weniger Fehler)
- âœ… **Schnellere Verarbeitung** (optimierte ParallelitÃ¤t)

---

## ğŸ”— Links

- **Quota-Management:** https://console.cloud.google.com/iam-admin/quotas
- **Billing:** https://console.cloud.google.com/billing
- **Vertex AI Quotas:** https://cloud.google.com/vertex-ai/docs/quotas
- **Gemini API Quotas:** https://cloud.google.com/vertex-ai/generative-ai/docs/quotas

