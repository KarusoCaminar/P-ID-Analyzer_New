# ğŸ§ª Pretraining Test Guide

**Datum:** 2025-11-06  
**Status:** âœ… Konfiguriert und bereit

---

## ğŸ“‹ Ãœbersicht

Dieses Dokument beschreibt, wie das Pretraining (Symbolvortraining) getestet und ausgewertet wird, **BEVOR** Viewshots generiert werden.

---

## ğŸ¯ Was macht Pretraining?

Das Pretraining-Skript (`run_pretraining.py`):

1. **Verarbeitet alle Bilder** in `training_data/pretraining_symbols/`
2. **Erkennt automatisch**, ob Bilder Sammlungen (groÃŸ) oder einzelne Symbole sind
3. **Extrahiert Symbole** aus Sammlungen automatisch (z.B. aus PDF-Sammlung)
4. **Integriert Symbole** in die Symbol-Bibliothek mit Duplikat-PrÃ¼fung
5. **Speichert** in Learning Database (`learning_db.json`)

---

## ğŸ§ª Pretraining testen

### Voraussetzungen

1. **GCP-Credentials setzen:**
   ```powershell
   $env:GCP_PROJECT_ID='dein_project_id'
   $env:GCP_LOCATION='us-central1'
   ```

2. **Pretraining-Verzeichnis prÃ¼fen:**
   - `training_data/pretraining_symbols/` sollte existieren
   - EnthÃ¤lt Symbol-Bilder (z.B. `Pid-symbols-PDF_sammlung.png`)

### Test ausfÃ¼hren

```bash
# Test-Skript ausfÃ¼hren (mit Auswertung)
python scripts/training/test_pretraining.py

# Oder direkt Pretraining ausfÃ¼hren
python scripts/training/run_pretraining.py
```

### Was wird getestet?

1. **Symbol-Extraktion:**
   - Werden Symbole aus Sammlungen korrekt extrahiert?
   - Werden einzelne Symbole korrekt verarbeitet?

2. **Symbol-Integration:**
   - Werden Symbole korrekt in die Bibliothek integriert?
   - Werden Duplikate korrekt erkannt?

3. **Learning Database:**
   - Werden Symbole korrekt in `learning_db.json` gespeichert?

---

## ğŸ“Š Test-Ergebnisse

### Output-Ordnerstruktur

```
outputs/pretraining_tests/
â”œâ”€â”€ test_pretraining_YYYYMMDD_HHMMSS.log    # Test-Logs
â””â”€â”€ test_results_YYYYMMDD_HHMMSS.json        # Test-Ergebnisse
```

### Test-Ergebnisse JSON

```json
{
  "timestamp": "2025-11-06T16:30:00",
  "success": true,
  "errors": [],
  "warnings": [],
  "metrics": {
    "files_found": 1,
    "initial_symbol_count": 0,
    "final_symbol_count": 150,
    "symbols_added": 150,
    "symbols_updated": 0,
    "duplicates_found": 5
  },
  "symbols_extracted": 1,
  "symbols_learned": 150,
  "collections_processed": 1,
  "individual_symbols_processed": 0
}
```

### Metriken

- **files_found:** Anzahl gefundener Bilddateien
- **initial_symbol_count:** Anzahl Symbole vor Pretraining
- **final_symbol_count:** Anzahl Symbole nach Pretraining
- **symbols_added:** Anzahl neu hinzugefÃ¼gter Symbole
- **symbols_updated:** Anzahl aktualisierter Symbole
- **duplicates_found:** Anzahl gefundener Duplikate
- **symbols_extracted:** Anzahl extrahierter Symbole
- **symbols_learned:** Anzahl gelernte Symbole
- **collections_processed:** Anzahl verarbeiteter Sammlungen
- **individual_symbols_processed:** Anzahl verarbeiteter einzelner Symbole

---

## ğŸ” Pretraining auswerten

### 1. Symbol-Extraktion prÃ¼fen

```python
# Beispiel: Test-Ergebnisse laden
import json
from pathlib import Path

results_file = Path("outputs/pretraining_tests/test_results_*.json")
with open(results_file, 'r') as f:
    results = json.load(f)

# PrÃ¼fe Extraktion
print(f"Symbols extracted: {results['symbols_extracted']}")
print(f"Symbols learned: {results['symbols_learned']}")
print(f"Collections processed: {results['collections_processed']}")
```

### 2. Learning Database prÃ¼fen

```python
# Beispiel: Learning Database laden
import json
from pathlib import Path

learning_db = Path("learning_db.json")
with open(learning_db, 'r') as f:
    db = json.load(f)

# PrÃ¼fe Symbole
symbols = db.get('symbols', [])
print(f"Total symbols in database: {len(symbols)}")

# PrÃ¼fe Symbol-Typen
symbol_types = {}
for symbol in symbols:
    symbol_type = symbol.get('type', 'unknown')
    symbol_types[symbol_type] = symbol_types.get(symbol_type, 0) + 1

print("Symbol types:")
for symbol_type, count in symbol_types.items():
    print(f"  {symbol_type}: {count}")
```

### 3. Fehler prÃ¼fen

```python
# Beispiel: Fehler prÃ¼fen
if results['errors']:
    print(f"Errors encountered: {len(results['errors'])}")
    for error in results['errors']:
        print(f"  - {error}")
```

---

## âš ï¸ HÃ¤ufige Probleme

### 1. Pretraining hÃ¤ngt

**Problem:** Das Skript hÃ¤ngt bei der Symbol-Extraktion.

**Ursachen:**
- LLM-API-Latenz (kann bei vielen Symbolen lange dauern)
- GroÃŸe Sammlungen (z.B. PDF-Sammlung mit 100+ Symbolen)
- Netzwerkprobleme

**LÃ¶sung:**
- PrÃ¼fe Logs: `outputs/pretraining_tests/test_pretraining_*.log`
- PrÃ¼fe LLM-API-Status
- Reduziere Anzahl Symbole pro Durchlauf

### 2. Keine Symbole extrahiert

**Problem:** Keine Symbole werden extrahiert.

**Ursachen:**
- Falsche Bildformate
- Zu kleine/groÃŸe Bilder
- Fehlende LLM-API-Credentials

**LÃ¶sung:**
- PrÃ¼fe Bildformate (PNG, JPG, JPEG)
- PrÃ¼fe BildgrÃ¶ÃŸe (min. 50x50 Pixel)
- PrÃ¼fe GCP-Credentials

### 3. Duplikate nicht erkannt

**Problem:** Duplikate werden nicht erkannt.

**Ursachen:**
- Falsche Duplikat-Erkennung
- Ã„hnliche aber unterschiedliche Symbole

**LÃ¶sung:**
- PrÃ¼fe Duplikat-Erkennungs-Logik
- Manuelle PrÃ¼fung der Symbole

---

## ğŸ“ˆ NÃ¤chste Schritte

### Nach erfolgreichem Pretraining

1. **Viewshots generieren:**
   ```bash
   python scripts/utilities/extract_viewshots_from_uni_bilder.py
   ```

2. **Viewshots testen:**
   - PrÃ¼fe, ob Viewshots korrekt generiert wurden
   - PrÃ¼fe, ob Viewshots in Prompts verwendet werden

3. **Pipeline testen:**
   - FÃ¼hre Tests mit Viewshots aus
   - Vergleiche Performance mit/ohne Viewshots

---

## âœ… Checkliste

### Vor Pretraining

- [ ] GCP-Credentials gesetzt
- [ ] Pretraining-Verzeichnis vorhanden
- [ ] Symbol-Bilder vorhanden
- [ ] Learning Database vorhanden

### Nach Pretraining

- [ ] Test erfolgreich abgeschlossen
- [ ] Symbole in Learning Database gespeichert
- [ ] Test-Ergebnisse gespeichert
- [ ] Fehler geprÃ¼ft und behoben

---

## ğŸ¯ Zusammenfassung

1. **Pretraining testen:** `python scripts/training/test_pretraining.py`
2. **Ergebnisse prÃ¼fen:** `outputs/pretraining_tests/test_results_*.json`
3. **Learning Database prÃ¼fen:** `learning_db.json`
4. **Viewshots generieren:** Nach erfolgreichem Pretraining
5. **Pipeline testen:** Mit Viewshots

---

**Status:** âœ… **Bereit fÃ¼r Pretraining-Test**

