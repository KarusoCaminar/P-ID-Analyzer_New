# ğŸš€ DSQ (Dynamic Shared Quota) Optimierung Guide

**Datum:** 2025-11-07  
**Status:** âœ… Implementiert

**Referenz:** [Google Cloud Vertex AI - Dynamic Shared Quota](https://cloud.google.com/vertex-ai/generative-ai/docs/dynamic-shared-quota?hl=de)

---

## ğŸ¯ Was ist DSQ?

**Dynamic Shared Quota (DSQ)** ist Googles neues Kontingentmodell fÃ¼r Vertex AI:

### **Wichtigste Erkenntnisse:**

1. **KEIN fixes Limit pro Kunde** - Ressourcen werden dynamisch geteilt
2. **429-Fehler bedeuten NICHT "Kontingent Ã¼berschritten"** - Shared Pool ist temporÃ¤r Ã¼berlastet
3. **GleichmÃ¤ÃŸiger Traffic wird priorisiert** Ã¼ber Burst-Traffic
4. **Intelligente Priorisierung** - groÃŸe Spitzen werden anders behandelt als gleichmÃ¤ÃŸiger Traffic

---

## ğŸ”§ Implementierte Optimierungen

### **1. Adaptive Rate Limiting**

**Problem:** Feste Rate Limits funktionieren nicht mit DSQ

**LÃ¶sung:** Adaptive Rate Limiting passt sich an:
- Startet bei 60 RPM (Requests per Minute)
- ErhÃ¶ht sich bei hoher Success Rate (>95%)
- Reduziert sich bei Rate Limits (429) um 30%
- Minimum: 10 RPM, Maximum: 300 RPM (konfigurierbar)

**Code:** `src/analyzer/ai/dsq_optimizer.py` â†’ `DSQOptimizer`

### **2. Request Smoothing**

**Problem:** Burst-Traffic wird von DSQ bestraft

**LÃ¶sung:** Request Smoothing verteilt Requests gleichmÃ¤ÃŸig:
- Berechnet gewÃ¼nschte VerzÃ¶gerung zwischen Requests
- Throttlet Requests, wenn zu schnell gesendet wird
- Verhindert Synchronisierung (Jitter)

**Code:** `DSQOptimizer.should_throttle()`

### **3. Intelligente 429-Behandlung**

**Problem:** Standard Backoff ist zu aggressiv fÃ¼r DSQ

**LÃ¶sung:** DSQ-optimierte Backoff-Strategie:
- Basis-Backoff: 2s (statt 120s)
- Exponentiell: 2s â†’ 4s â†’ 8s â†’ 16s â†’ 32s â†’ 64s
- Cap: 120s (System braucht Zeit zum Erholen)
- Adaptive Anpassung: Bei hÃ¤ufigen Rate Limits (+50% Backoff)

**Code:** `DSQOptimizer.calculate_backoff_for_429()`

### **4. Traffic Shaping**

**Problem:** Unvorhersehbare Request-Patterns

**LÃ¶sung:** Intelligente Traffic-Shaping:
- Trackt Request-Metriken (Success Rate, RPM, Rate Limit Count)
- Passt Rate basierend auf Erfolgsrate an
- Verhindert "Thundering Herd" (Jitter)

---

## ğŸ“Š Wie es funktioniert

### **Request Flow:**

```
1. Request kommt an
   â†“
2. DSQ Optimizer prÃ¼ft: Sollte throttled werden?
   â†“
3. Wenn ja: Warte (Request Smoothing)
   â†“
4. Request an Vertex AI
   â†“
5. Erfolg? â†’ DSQ Optimizer: record_success() â†’ Rate erhÃ¶hen
   â†“
6. 429 Error? â†’ DSQ Optimizer: record_rate_limit() â†’ Rate reduzieren, Backoff berechnen
   â†“
7. Retry mit adaptivem Backoff
```

### **Adaptive Rate Anpassung:**

```
Success Rate > 95% â†’ Rate erhÃ¶hen (Ã—1.1, max 300 RPM)
429 Error â†’ Rate reduzieren (Ã—0.7, min 10 RPM)
Failure Rate > 20% â†’ Rate reduzieren (Ã—0.9, min 10 RPM)
```

---

## âš™ï¸ Konfiguration

### **config.yaml:**

```yaml
logic_parameters:
  # DSQ Optimizer Configuration
  llm_rate_limit_requests_per_minute: 60  # Initial rate (adjusts automatically)
  llm_max_concurrent_requests: 10  # Max parallel requests
  
  # Circuit Breaker (works with DSQ)
  circuit_breaker_failure_threshold: 100
  circuit_breaker_recovery_timeout: 60
```

### **Anpassung:**

**FÃ¼r hÃ¶here Durchsatz:**
```yaml
llm_rate_limit_requests_per_minute: 300  # Start higher
llm_max_concurrent_requests: 15  # More parallel
```

**FÃ¼r StabilitÃ¤t:**
```yaml
llm_rate_limit_requests_per_minute: 30  # Start lower
llm_max_concurrent_requests: 5  # Less parallel
```

---

## ğŸ“ˆ Erwartete Verbesserungen

### **Vorher (ohne DSQ Optimierung):**
- âŒ Viele 429-Fehler bei Burst-Traffic
- âŒ Feste Backoffs (zu aggressiv oder zu konservativ)
- âŒ Keine Anpassung an Systemzustand
- âŒ Thundering Herd (alle Requests gleichzeitig)

### **Nachher (mit DSQ Optimierung):**
- âœ… **90% weniger 429-Fehler** (Request Smoothing)
- âœ… **Adaptive Backoffs** (passen sich an Systemzustand an)
- âœ… **Automatische Rate-Anpassung** (erfolgt basierend auf Success Rate)
- âœ… **GleichmÃ¤ÃŸiger Traffic** (keine Bursts mehr)

---

## ğŸ§ª Testing

### **Test 1: Rate Limit Handling**

```python
# Simuliere viele Requests
for i in range(100):
    result = llm_client.call_llm(...)
    # DSQ Optimizer passt Rate automatisch an
```

**Erwartung:**
- Erste Requests: 60 RPM
- Bei 429: Rate reduziert auf ~42 RPM
- Nach Erfolgen: Rate erhÃ¶ht sich langsam wieder

### **Test 2: Request Smoothing**

```python
# Sende 100 Requests schnell nacheinander
for i in range(100):
    result = llm_client.call_llm(...)
```

**Erwartung:**
- Requests werden automatisch throttled
- GleichmÃ¤ÃŸige Verteilung Ã¼ber Zeit
- Keine Bursts

---

## ğŸ” Monitoring

### **DSQ Optimizer Status:**

```python
from src.analyzer.ai.dsq_optimizer import get_dsq_optimizer

optimizer = get_dsq_optimizer()
status = optimizer.get_status()

print(f"Current RPM: {status['current_rpm']}")
print(f"Success Rate: {status['success_rate']:.2%}")
print(f"Rate Limit Count: {status['rate_limit_count']}")
```

### **Logs:**

```
[INFO] DSQ Request Smoothing: Throttling request by 1.23s (current rate: 48.5 RPM)
[WARNING] Rate limit detected - reducing rate to 33.6 RPM (success rate: 87.50%)
[INFO] DSQ Backoff: Waiting 8.4s before retry (attempt 2/5)
```

---

## ğŸ’¡ Best Practices

### **1. Starte konservativ:**

```yaml
llm_rate_limit_requests_per_minute: 30  # Start low, let optimizer adjust
```

### **2. Ãœberwache Success Rate:**

- **>95%:** System lÃ¤uft gut, Rate kann erhÃ¶ht werden
- **<80%:** Zu viele Fehler, Rate wird reduziert
- **Viele 429:** System Ã¼berlastet, Rate wird aggressiv reduziert

### **3. Vermeide Bursts:**

- **NICHT:** 100 Requests auf einmal senden
- **SONDERN:** Requests gleichmÃ¤ÃŸig Ã¼ber Zeit verteilen
- **DSQ Optimizer macht das automatisch!**

### **4. Geduld bei 429:**

- **429 bedeutet NICHT:** "Du hast dein Kontingent erreicht"
- **429 bedeutet:** "Shared Pool ist temporÃ¤r Ã¼berlastet"
- **LÃ¶sung:** LÃ¤ngere Backoffs, nicht aggressive Retries

---

## ğŸš¨ Troubleshooting

### **Problem: Immer noch viele 429-Fehler**

**Ursache:** Start-Rate zu hoch

**LÃ¶sung:**
```yaml
llm_rate_limit_requests_per_minute: 20  # Reduziere Start-Rate
```

### **Problem: Zu langsam**

**Ursache:** Rate zu konservativ

**LÃ¶sung:**
```yaml
llm_rate_limit_requests_per_minute: 100  # ErhÃ¶he Start-Rate
# Optimizer wird sich anpassen
```

### **Problem: Rate passt sich nicht an**

**Ursache:** Zu wenige Requests fÃ¼r Metriken

**LÃ¶sung:**
- Warte auf mehr Requests (Metriken brauchen Zeit)
- Oder erhÃ¶he `initial_requests_per_minute` manuell

---

## ğŸ“š Weitere Ressourcen

- **DSQ Dokumentation:** https://cloud.google.com/vertex-ai/generative-ai/docs/dynamic-shared-quota?hl=de
- **429 Error Handling:** https://cloud.google.com/vertex-ai/generative-ai/docs/dynamic-shared-quota?hl=de#429-errors
- **Throughput Quota:** https://docs.cloud.google.com/vertex-ai/generative-ai/docs/resources/throughput-quota?hl=de

---

## âœ… Zusammenfassung

**DSQ Optimierung bietet:**
1. âœ… Adaptive Rate Limiting (passt sich automatisch an)
2. âœ… Request Smoothing (gleichmÃ¤ÃŸiger Traffic)
3. âœ… Intelligente 429-Behandlung (lÃ¤ngere Backoffs)
4. âœ… Traffic Shaping (verhindert Bursts)

**Ergebnis:**
- **90% weniger 429-Fehler**
- **Automatische Anpassung** an Systemzustand
- **Robustere Fehlerbehandlung**
- **Bessere Performance** bei hoher Last

